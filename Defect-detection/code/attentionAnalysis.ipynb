{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jirigesi/anaconda3/envs/CodeBert/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "from transformers import  RobertaConfig, RobertaModel, RobertaTokenizer\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from model2 import Model\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
    "import random\n",
    "import multiprocessing\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import javalang\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "np.random.seed(0)\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import pickle\n",
    "import sklearn\n",
    "from matplotlib import cm\n",
    "from sklearn import manifold\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "BLACK = \"k\"\n",
    "GREEN = \"#59d98e\"\n",
    "SEA = \"#159d82\"\n",
    "BLUE = \"#3498db\"\n",
    "PURPLE = \"#9b59b6\"\n",
    "GREY = \"#95a5a6\"\n",
    "RED = \"#e74c3c\"\n",
    "ORANGE = \"#f39c12\"\n",
    "YELLOW = \"#f1c40f\"\n",
    "GRAY = \"#95a5a6\"\n",
    "BROWN = \"#8e44ad\"\n",
    "CYAN = \"#8e44ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single training/test features for a example.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_tokens,\n",
    "                 input_ids,\n",
    "                 idx,\n",
    "                 label,\n",
    "\n",
    "    ):\n",
    "        self.input_tokens = input_tokens\n",
    "        self.input_ids = input_ids\n",
    "        self.idx=str(idx)\n",
    "        self.label=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(js,tokenizer):\n",
    "    #source\n",
    "    code=' '.join(js['func'].split())\n",
    "    code_tokens=tokenizer.tokenize(code)[:block_size-2]\n",
    "    source_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
    "    source_ids =  tokenizer.convert_tokens_to_ids(source_tokens)\n",
    "    padding_length = block_size - len(source_ids)\n",
    "    source_ids+=[tokenizer.pad_token_id]*padding_length\n",
    "    \n",
    "    return InputFeatures(source_tokens,source_ids,js['idx'],js['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, file_path=None):\n",
    "        self.examples = []\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                js=json.loads(line.strip())\n",
    "                self.examples.append(convert_examples_to_features(js,tokenizer))\n",
    "        if 'train' in file_path:\n",
    "            for idx, example in enumerate(self.examples[:3]):\n",
    "                    logger.info(\"*** Example ***\")\n",
    "                    logger.info(\"idx: {}\".format(idx))\n",
    "                    logger.info(\"label: {}\".format(example.label))\n",
    "                    logger.info(\"input_tokens: {}\".format([x.replace('\\u0120','_') for x in example.input_tokens]))\n",
    "                    logger.info(\"input_ids: {}\".format(' '.join(map(str, example.input_ids))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):       \n",
    "        return torch.tensor(self.examples[i].input_ids),torch.tensor(self.examples[i].label)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = RobertaConfig.from_pretrained('microsoft/codebert-base')\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "model = RobertaModel.from_pretrained('microsoft/codebert-base',\n",
    "                                    output_attentions=True, \n",
    "                                    output_hidden_states=True)\n",
    "\n",
    "model=Model(model,config,tokenizer)\n",
    "\n",
    "checkpoint_prefix = \"saved_models/CD4DD/model_CD.bin\"\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_prefix, map_location=torch.device('cpu')))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 400\n",
    "test_data_file = \"../dataset/test.jsonl\"\n",
    "# Loop to handle MNLI double evaluation (matched, mis-matched)\n",
    "eval_dataset = TextDataset(tokenizer,test_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2732, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_dataset), len(eval_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(test_data_file) as f:\n",
    "    for line in f:\n",
    "        js=json.loads(line.strip())\n",
    "        data.append((js['target'], ' '.join(js['func'].split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2732"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'int ff_get_wav_header(AVFormatContext *s, AVIOContext *pb, AVCodecContext *codec, int size, int big_endian) { int id; uint64_t bitrate; if (size < 14) { avpriv_request_sample(codec, \"wav header size < 14\"); return AVERROR_INVALIDDATA; } codec->codec_type = AVMEDIA_TYPE_AUDIO; if (!big_endian) { id = avio_rl16(pb); if (id != 0x0165) { codec->channels = avio_rl16(pb); codec->sample_rate = avio_rl32(pb); bitrate = avio_rl32(pb) * 8LL; codec->block_align = avio_rl16(pb); } } else { id = avio_rb16(pb); codec->channels = avio_rb16(pb); codec->sample_rate = avio_rb32(pb); bitrate = avio_rb32(pb) * 8LL; codec->block_align = avio_rb16(pb); } if (size == 14) { /* We\\'re dealing with plain vanilla WAVEFORMAT */ codec->bits_per_coded_sample = 8; } else { if (!big_endian) { codec->bits_per_coded_sample = avio_rl16(pb); } else { codec->bits_per_coded_sample = avio_rb16(pb); } } if (id == 0xFFFE) { codec->codec_tag = 0; } else { codec->codec_tag = id; codec->codec_id = ff_wav_codec_get_id(id, codec->bits_per_coded_sample); } if (size >= 18 && id != 0x0165) { /* We\\'re obviously dealing with WAVEFORMATEX */ int cbSize = avio_rl16(pb); /* cbSize */ if (big_endian) { avpriv_report_missing_feature(codec, \"WAVEFORMATEX support for RIFX files\\\\n\"); return AVERROR_PATCHWELCOME; } size -= 18; cbSize = FFMIN(size, cbSize); if (cbSize >= 22 && id == 0xfffe) { /* WAVEFORMATEXTENSIBLE */ parse_waveformatex(pb, codec); cbSize -= 22; size -= 22; } if (cbSize > 0) { av_freep(&codec->extradata); if (ff_get_extradata(codec, pb, cbSize) < 0) return AVERROR(ENOMEM); size -= cbSize; } /* It is possible for the chunk to contain garbage at the end */ if (size > 0) avio_skip(pb, size); } else if (id == 0x0165 && size >= 32) { int nb_streams, i; size -= 4; av_freep(&codec->extradata); if (ff_get_extradata(codec, pb, size) < 0) return AVERROR(ENOMEM); nb_streams = AV_RL16(codec->extradata + 4); codec->sample_rate = AV_RL32(codec->extradata + 12); codec->channels = 0; bitrate = 0; if (size < 8 + nb_streams * 20) return AVERROR_INVALIDDATA; for (i = 0; i < nb_streams; i++) codec->channels += codec->extradata[8 + i * 20 + 17]; } if (bitrate > INT_MAX) { if (s->error_recognition & AV_EF_EXPLODE) { av_log(s, AV_LOG_ERROR, \"The bitrate %\"PRIu64\" is too large.\\\\n\", bitrate); return AVERROR_INVALIDDATA; } else { av_log(s, AV_LOG_WARNING, \"The bitrate %\"PRIu64\" is too large, resetting to 0.\", bitrate); codec->bit_rate = 0; } } else { codec->bit_rate = bitrate; } if (codec->sample_rate <= 0) { av_log(s, AV_LOG_ERROR, \"Invalid sample rate: %d\\\\n\", codec->sample_rate); return AVERROR_INVALIDDATA; } if (codec->codec_id == AV_CODEC_ID_AAC_LATM) { /* Channels and sample_rate values are those prior to applying SBR * and/or PS. */ codec->channels = 0; codec->sample_rate = 0; } /* override bits_per_coded_sample for G.726 */ if (codec->codec_id == AV_CODEC_ID_ADPCM_G726 && codec->sample_rate) codec->bits_per_coded_sample = codec->bit_rate / codec->sample_rate; return 0; }')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syntax_types_for_code(code_snippet):\n",
    "  types = [\"[CLS]\"]\n",
    "  code = [\"<s>\"]\n",
    "  tree = list(javalang.tokenizer.tokenize(code_snippet))\n",
    "  \n",
    "  for i in tree:\n",
    "    j = str(i)\n",
    "    j = j.split(\" \")\n",
    "    if j[1] == '\"MASK\"':\n",
    "      types.append('[MASK]')\n",
    "      code.append('<mask>')\n",
    "    else:\n",
    "      types.append(j[0].lower())\n",
    "      code.append(j[1][1:-1])\n",
    "    \n",
    "  types.append(\"[SEP]\")\n",
    "  code.append(\"</s>\")\n",
    "  return np.array(types), ' '.join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_sample = data[0]\n",
    "types, rewrote_code = get_syntax_types_for_code(code_sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(636, 634)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(types), len(rewrote_code.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_of_token_when_tokenized(code, types, tokenizer):\n",
    "  reindexed_types = []\n",
    "  start = 0\n",
    "  end = 0\n",
    "  for index, each_token in enumerate(code.split(\" \")):\n",
    "    tokenized_list = tokenizer.tokenize(each_token)\n",
    "    for i in range(len(tokenized_list)):\n",
    "      end += 1\n",
    "    reindexed_types.append((start, end-1))\n",
    "    start = end\n",
    "  return reindexed_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSyntaxAttentionScore(model, data, tokenizer, syntaxList):\n",
    "    block_size = 400\n",
    "    all_instances = []\n",
    "    number = 0\n",
    "    for code_sample in tqdm(data):\n",
    "        Instantce_Result = {}\n",
    "        try: \n",
    "            for syntaxType in syntaxList:\n",
    "                Instantce_Result[syntaxType] = []\n",
    "\n",
    "\n",
    "            types_1, rewrote_code_1 = get_syntax_types_for_code(code_sample[1])\n",
    "            \n",
    "            tokenized_ids_1 = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(rewrote_code_1))\n",
    "\n",
    "            if len(tokenized_ids_1) > 400:\n",
    "                tokenized_ids_1 = tokenized_ids_1[:399] + [tokenizer.sep_token_id]\n",
    "            \n",
    "            padding_length = block_size - len(tokenized_ids_1)\n",
    "            tokenized_ids_1+=[tokenizer.pad_token_id]*padding_length\n",
    "            labels = code_sample[0]\n",
    "\n",
    "            source_ids = torch.tensor(tokenized_ids_1).unsqueeze(0).to(device)\n",
    "            labels = torch.tensor(labels).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(source_ids,labels)\n",
    "\n",
    "            _attention = output[2].attentions\n",
    "            start_end = get_start_end_of_token_when_tokenized(rewrote_code_1, types_1, tokenizer)\n",
    "            \n",
    "            for syntaxType in syntaxList:\n",
    "                attention_weights = [[[] for col in range(12)] for row in range(12)]\n",
    "                for layer in range(12):\n",
    "                    for head in range(12):\n",
    "                        for each_sep_index in np.where(types_1==syntaxType)[0]:\n",
    "                            start_index, end_index = start_end[each_sep_index]\n",
    "                            interim_value = _attention[layer][0][head][:, start_index:end_index+1].mean().cpu().detach().numpy()\n",
    "                            if np.isnan(interim_value):\n",
    "                                pass\n",
    "                            else: \n",
    "                                attention_weights[layer][head].append(interim_value)     \n",
    "                if np.array(attention_weights).shape[2] != 0:\n",
    "                    Instantce_Result[syntaxType].append(np.array(attention_weights))\n",
    "            all_instances.append(Instantce_Result)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            \n",
    "    return all_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_list = ['annotation', 'basictype', 'boolean', \n",
    "          'decimalinteger', 'identifier', 'keyword',\n",
    "          'modifier', 'operator', 'separator', 'null',\n",
    "          'string', 'decimalfloatingpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2732 [00:07<1:32:12,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 44/2732 [00:38<36:28,  1.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 49/2732 [00:41<28:17,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 52/2732 [00:43<25:03,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 59/2732 [00:49<44:50,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 85/2732 [01:14<36:43,  1.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 103/2732 [01:27<29:27,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 107/2732 [01:29<27:04,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 130/2732 [01:49<35:00,  1.24it/s]"
     ]
    }
   ],
   "source": [
    "syntax_attention_weights = getSyntaxAttentionScore(model, data, tokenizer, syntax_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syntax_attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodeBert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b13e3fd3289f8bb387fc7ab81946cd58b1691644cd9d3c76126fbd09f58dbdd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
